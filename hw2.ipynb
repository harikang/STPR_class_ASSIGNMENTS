{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHot(y_in, K ):    \n",
    "    encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
    "    y = y_in\n",
    "    # pandas DataFrame to  numpy array\n",
    "    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "        y = y.to_numpy()\n",
    "        # OneHotEncoding\n",
    "        y = y.reshape(-1, 1) \n",
    "        y_out = encoder.fit_transform(y)\n",
    "    elif isinstance(y, pd.DataFrame) and all(y.dtypes == object):\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y)\n",
    "        labels_reshaped = np.array(y).reshape(-1, 1)\n",
    "        y_out = encoder.fit_transform(labels_reshaped)\n",
    "    else:\n",
    "        y = y.reshape(-1, 1) \n",
    "        y_out = encoder.fit_transform(y)\n",
    "    \n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "iris_X = iris.data.features \n",
    "iris_y = iris.data.targets \n",
    "# Normalize X\n",
    "scaler = StandardScaler()\n",
    "iris_X = scaler.fit_transform(iris_X)\n",
    "label_encoder = LabelEncoder()\n",
    "int_iris_y = label_encoder.fit_transform(iris_y)\n",
    "onehot_iris_y = OneHot(iris_y,3)\n",
    "\n",
    "# 결과 출력 (선택 사항)\n",
    "print(\"Encoded Features Shape:\", iris_X.shape)\n",
    "print(\"Targets Shape:\", int_iris_y.shape)\n",
    "print(\"OneHot Encoded Targets Shape:\", onehot_iris_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df):\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    \n",
    "    encoded_df = pd.DataFrame(encoder.fit_transform(df[categorical_cols]))\n",
    "    encoded_df.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "    \n",
    "    df = df.drop(categorical_cols, axis=1)\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset\n",
    "mushroom = fetch_ucirepo(id=73) \n",
    "mushroom_X = mushroom.data.features\n",
    "mushroom_y = mushroom.data.targets\n",
    "\n",
    "mushroom_X = encode_categorical_features(mushroom_X)\n",
    "\n",
    "# Normalize X\n",
    "scaler = StandardScaler()\n",
    "mushroom_X = scaler.fit_transform(mushroom_X)\n",
    "label_encoder = LabelEncoder()\n",
    "int_mushroom_y = label_encoder.fit_transform(mushroom_y)\n",
    "onehot_mushroom_y = OneHot(mushroom_y,2)\n",
    "\n",
    "\n",
    "# 결과 출력 (선택 사항)\n",
    "print(\"Encoded Features Shape:\", mushroom_X.shape)\n",
    "print(\"Targets Shape:\", int_mushroom_y.shape)\n",
    "print(\"OneHot Encoded Targets Shape:\", onehot_mushroom_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "optical_recognition_of_handwritten_digits_X = optical_recognition_of_handwritten_digits.data.features \n",
    "optical_recognition_of_handwritten_digits_y = optical_recognition_of_handwritten_digits.data.targets \n",
    "\n",
    "optical_recognition_of_handwritten_digits_X = encode_categorical_features(optical_recognition_of_handwritten_digits_X)\n",
    "# Normalize X\n",
    "scaler = StandardScaler()\n",
    "digits_X = scaler.fit_transform(optical_recognition_of_handwritten_digits_X)\n",
    "int_digits_y = optical_recognition_of_handwritten_digits_y.to_numpy().reshape(-1)\n",
    "onehot_digits_y = OneHot(optical_recognition_of_handwritten_digits_y,10)\n",
    "\n",
    "# 결과 출력 (선택 사항)\n",
    "print(\"Encoded Features Shape:\", digits_X.shape)\n",
    "print(\"Targets Shape:\", int_digits_y.shape)\n",
    "print(\"OneHot Encoded Targets Shape:\", onehot_digits_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cross_validate(model, X, y, folds=5):\n",
    "    kf = KFold(n_splits=folds)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        val = model.score(X_test, y_test) *100\n",
    "        results.append(val.round(2))\n",
    "    print(results)\n",
    "    ans = np.mean(results)\n",
    "    return ans.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetlist=[[\"Digits\",digits_X,onehot_digits_y],[\"Mushroom\",mushroom_X,onehot_mushroom_y],[\"IRIS\",iris_X,onehot_iris_y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example settings for 3-layer MLP\n",
    "hidden_node_sizes = [128, 64, 32]\n",
    "epochs = 100  # Increase the number of epochs\n",
    "\n",
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Train and evaluate models\n",
    "for set_name, X, y in datasetlist:\n",
    "    print(set_name)\n",
    "    for hidden_nodes in hidden_node_sizes:   \n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(hidden_nodes, hidden_nodes), \n",
    "            max_iter=epochs, \n",
    "            activation='relu',\n",
    "            learning_rate_init=1e-3,\n",
    "            random_state=42\n",
    "        )\n",
    "        scores = cross_validate(model, X, y)\n",
    "        \n",
    "        # Print the mean accuracy and standard deviation\n",
    "        print(f\"Nodes: {hidden_nodes}, Score: {scores:.2f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetlist=[[\"Digits\",digits_X,int_digits_y],[\"Mushroom\",mushroom_X,int_mushroom_y],[\"IRIS\",iris_X,int_iris_y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example settings for SVM\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "degrees = [2, 3]  # Only for polynomial kernel\n",
    "gammas = [0.01, 0.1, 1]  # Only for RBF kernel\n",
    "# Loop through all combinations (example)\n",
    "for set_name, X, y in datasetlist:\n",
    "    print(set_name)\n",
    "    for kernel in kernels:\n",
    "        if kernel == 'poly':\n",
    "            for degree in degrees:\n",
    "                model = SVC(kernel=kernel, C=1, degree=degree)\n",
    "                score = cross_validate(model, X, y)\n",
    "                print(f\"Kernel: {kernel}, Degree: {degree}, Score: {score:.2f}\")\n",
    "        elif kernel == 'rbf':\n",
    "            for gamma in gammas:\n",
    "                model = SVC(kernel=kernel, C=1, gamma=gamma)\n",
    "                score = cross_validate(model, X, y)\n",
    "                print(f\"Kernel: {kernel}, Gamma: {gamma}, Score: {score:.2f}\")\n",
    "        else:\n",
    "            model = SVC(kernel=kernel, C=1)\n",
    "            score = cross_validate(model, X, y)\n",
    "            print(f\"Kernel: {kernel}, Score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RM(X, order):\n",
    "    # Build regressor matrix P (mxK):\n",
    "    # order = desired order of approximation,\n",
    "    # X = input matrix (mxl), K = number of parameters to be est.\n",
    "    # m = number of data samples, l = input dimension.\n",
    "    m, l = X.shape\n",
    "    MM1 = []\n",
    "    MM3 = []\n",
    "    Msum = np.sum(X, axis=1)\n",
    "    for i in range(1, order+1):\n",
    "        M1 = np.zeros((m, l))\n",
    "        M3 = np.zeros((m, l))\n",
    "        for k in range(l):\n",
    "            M1[:, k] = X[:, k]**i\n",
    "            if i > 1:\n",
    "                M3[:, k] = X[:, k] * Msum**(i-1)\n",
    "        MM1.append(M1)\n",
    "        if i > 1:\n",
    "            MM3.append(M3)\n",
    "    if MM3:\n",
    "        P = np.concatenate([np.ones((m, 1)), np.concatenate(MM1, axis=1), np.concatenate(MM3, axis=1)], axis=1)\n",
    "    else:\n",
    "        P = np.concatenate([np.ones((m, 1)), np.concatenate(MM1, axis=1)], axis=1)\n",
    "    return P\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "order = 2\n",
    "P = RM(X, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example settings for RM model\n",
    "orders = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Loop through all orders (example)\n",
    "for set_name, X, y in datasetlist:\n",
    "    print(set_name)\n",
    "    for order in orders:\n",
    "        P = RM(X, order)\n",
    "        # Perform linear regression\n",
    "        model = LogisticRegression()\n",
    "        score = cross_validate(model, P, y)\n",
    "        print(f\"Order: {order}, Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming results are stored in dictionaries\n",
    "results = {\n",
    "    'SVM': {'linear': 0.85, 'poly': 0.82, 'rbf': 0.87},\n",
    "    'MLP': {'10 nodes': 0.80, '20 nodes': 0.83, '50 nodes': 0.85},\n",
    "    'RM': {'order 1': 0.78, 'order 2': 0.81, 'order 3': 0.84, 'order 4': 0.86, 'order 5': 0.85}\n",
    "}\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "for model, scores in results.items():\n",
    "    print(f\"{model}:\")\n",
    "    for setting, score in scores.items():\n",
    "        print(f\"  {setting}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "datasetlist=[[\"Digits\",digits_X,int_digits_y],[\"Mushroom\",mushroom_X,int_mushroom_y],[\"IRIS\",iris_X,int_iris_y]]\n",
    "\n",
    "# Define a function to plot the average training results\n",
    "def plot_avg_training_results(X, y, dataset_name):\n",
    "    orders = range(1, 6)\n",
    "    order_result1, order_result2 = [],[]\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(25, 5), sharey=True)\n",
    "    \n",
    "    for idx, order in enumerate(orders):\n",
    "        P = RM(X, order)\n",
    "        model = LogisticRegression(max_iter=1000)        \n",
    "        kf = KFold(n_splits=5)\n",
    "        train_results, test_results = [],[]\n",
    "        \n",
    "        for train_index, test_index in kf.split(P):\n",
    "            X_train, X_test = P[train_index], P[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model.fit(X_train, y_train)\n",
    "            train = model.score(X_train,y_train) *100 \n",
    "            test = model.score(X_test, y_test) *100\n",
    "            train_results.append(train.round(2))\n",
    "            test_results.append(test.round(2))\n",
    "        \n",
    "        train_ans = np.mean(train_results)        \n",
    "        test_ans = np.mean(test_results)\n",
    "        order_result1.append(train_ans)\n",
    "        order_result2.append(test_ans)\n",
    "        \n",
    "        axes[idx].plot(range(1, len(train_results) + 1), train_results, marker='o', label='Training Accuracy')\n",
    "        axes[idx].plot(range(1, len(test_results) + 1), test_results, marker='x', label='Testing Accuracy')\n",
    "        axes[idx].set_title(f'Order: {order}')\n",
    "        axes[idx].set_xlabel('Fold')\n",
    "        axes[idx].set_ylabel('Accuracy')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True)\n",
    "    \n",
    "    fig.suptitle(f'Average Training and Testing Accuracy for {dataset_name}', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(orders, order_result1, marker='o', label='Average Training Accuracy')\n",
    "    plt.plot(orders, order_result2, marker='x', label='Average Testing Accuracy')\n",
    "    plt.title(f'Training and Testing 5-fold each Order Accuracy for {dataset_name}')\n",
    "    plt.xlabel('RM Order')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot average training results for each dataset\n",
    "for set_name, X, y in datasetlist:\n",
    "    print(set_name)\n",
    "    plot_avg_training_results(X, y, set_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
